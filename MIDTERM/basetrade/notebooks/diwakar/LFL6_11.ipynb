{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import copy\n",
      "\n",
      "import argparse\n",
      "\n",
      "import time\n",
      "from datetime import datetime\n",
      "from pandas.tseries.offsets import BDay\n",
      "\n",
      "from pandas.plotting import autocorrelation_plot\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "from statsmodels.tsa.arima_model import ARIMA\n",
      "import statsmodels.tsa.stattools as ts\n",
      "import statsmodels.api as sm\n",
      "\n",
      "import matplotlib.patches as mpatches\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "\n",
      "sys.path.append(os.path.expanduser('~/dvc-bardata-toolkit/'))\n",
      "\n",
      "import data_utils.data_info as di\n",
      "import signal_utils.signal_info as si\n",
      "\n",
      "\n",
      "from transform_utils.transform_info import make_changes\n",
      "from transform_utils.transform_info import make_ema_changes\n",
      "\n",
      "from datetime_utils.convert_datetime import get_timestamp_tuples\n",
      "from datetime_utils.convert_datetime import get_timestamp_tuples_cumulative\n",
      "from datetime_utils.convert_datetime import get_date_time_from_timestamp\n",
      "\n",
      "import utils.df_utils as ut\n",
      "from utils.trade_utils import TradeGenerator\n",
      "\n",
      "from utils.curve_utils import get_nearing_shortcodes\n",
      "from alphas.curve_alphas import compute_signal_print_trades\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parse(args):\n",
      "    parser = argparse.ArgumentParser()\n",
      "    parser.add_argument('-s', dest='shortcode_list', nargs='+', help='list of shortcodes to be used', required=True)\n",
      "    parser.add_argument('-st', dest='start_time', help='common start time', required=True)\n",
      "    parser.add_argument('-et', dest='end_time', help='common end time', required=True)\n",
      "    parser.add_argument('-sd', dest='start_date', help='common start date', required=False)\n",
      "    parser.add_argument('-ed', dest='end_date', help='common end date', required=False)\n",
      "    parser.add_argument('-sp', dest='signal_params', nargs='+', help='lag of returns duration', required=False)\n",
      "    parser.add_argument('--spread-distance', dest='spread_distance',help=' the distance between two maturities to be considered', required=False)\n",
      "    parser.add_argument('--duration', dest='pred_duration', help='prediction duration ')\n",
      "    parser.add_argument('--trade-type', dest='trade_type', help=' trade type we want SPREAD/FLY', required=True)\n",
      "    return parser.parse_args(args)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "string = '-s LFL_6:LFL_11 -st BST_700 -et BST_1800 -sd 20140101 -ed 20171006 --spread-distance 3 --trade-type SPREAD --duration 2h -sp 0.004 0.0025'\n",
      "arg_str = string.split()\n",
      "\n",
      "args = parse(arg_str)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shortcode_list_to_trade = [shortcode.split(':') for shortcode in args.shortcode_list]\n",
      "\n",
      "list_of_shc_to_trade = [shc for shc_list in shortcode_list_to_trade for shc in shc_list]\n",
      "\n",
      "start_time = args.start_time\n",
      "end_time = args.end_time\n",
      "\n",
      "start_date = int(args.start_date) if args.start_date else 20160101\n",
      "end_date = int(args.end_date) if args.end_date else 20170930\n",
      "\n",
      "signal_name = 'changes'\n",
      "signal_params = ''\n",
      "\n",
      "start_date = datetime.strptime(str(start_date), \"%Y%m%d\")\n",
      "end_date = datetime.strptime(str(end_date), \"%Y%m%d\")\n",
      "\n",
      "num_trade_hours = int(end_time[4:len(end_time)]) - int(start_time[4:len(start_time)])\n",
      "num_trade_hours /= 100.0\n",
      "\n",
      "print('NUM_TRADING_HOURS', num_trade_hours)\n",
      "\n",
      "while start_date.weekday() >= 5:\n",
      "    start_date += BDay(1)\n",
      "    \n",
      "spread_distance = int(args.spread_distance) if args.spread_distance else 1\n",
      "pred_duration = args.pred_duration if args.pred_duration else '1h'\n",
      "\n",
      "threshold_vec = list(map(float,args.signal_params))\n",
      "\n",
      "\n",
      "work_dir = os.path.expanduser(\"~/curve_trading/\") + '_'.join(list_of_shc_to_trade).lower() + '/' \\\n",
      "           + str(spread_distance) + '/' + pred_duration + '/'\n",
      "\n",
      "unique_id = time.time()\n",
      "work_dir += str(int(unique_id*1000))\n",
      "\n",
      "print(work_dir)\n",
      "os.system(\"mkdir --parents \" + work_dir)\n",
      "position_file_prefix = work_dir + \"pos_\"\n",
      "\n",
      "\n",
      "shortcode_list = copy.copy(list_of_shc_to_trade)\n",
      "\n",
      "symbol_list = copy.copy(shortcode_list)\n",
      "symbol_list = ['symbol_' + shc.lower() for shc in shortcode_list]\n",
      "\n",
      "shortcode_to_neibhors = {}\n",
      "\n",
      "print('Trading Proucts', ' '.join(list_of_shc_to_trade))\n",
      "if args.trade_type == 'FLY':\n",
      "    for shortcode in list_of_shc_to_trade:\n",
      "        higher = get_nearing_shortcodes(shortcode, 1*spread_distance)\n",
      "        lower = get_nearing_shortcodes(shortcode, -1*spread_distance)\n",
      "        if lower and higher:\n",
      "            shortcode_list += [higher, lower]\n",
      "            shortcode_to_neibhors[shortcode] = [lower, higher]\n",
      "elif args.trade_type == 'SPREAD':\n",
      "    if len(list_of_shc_to_trade) % 2 != 0:\n",
      "        print ('ERROR, Need Pairs for trading SPREAD')\n",
      "        \n",
      "shortcode_list = list(set(shortcode_list))\n",
      "\n",
      "print('All Shortcodes', ' '.join(shortcode_list))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start_end_keys = get_timestamp_tuples_cumulative(start_date.strftime(\"%Y%m%d\"), end_date.strftime(\"%Y%m%d\"))\n",
      "\n",
      "# get the pairs for each day\n",
      "daywise_start_end = list(get_timestamp_tuples(start_date.strftime('%Y%m%d'), end_date.strftime('%Y%m%d'), start_time, end_time))\n",
      "\n",
      "print('Trying Fetch Data ', ' '.join(shortcode_list), ' For Date ',start_date, ' ', end_date, ' ',\n",
      "      start_time,' ', end_time, ' ', start_end_keys[0], ' ', start_end_keys[1])\n",
      "\n",
      "all_prices_df = di.fetch_data(shortcode_list, ['open_price', 'symbol'], start_end_keys[0], start_end_keys[1])\n",
      "\n",
      "print(daywise_start_end)\n",
      "date = start_date\n",
      "map_prices_df = {}\n",
      "symbol_df = {}\n",
      "map_date_unix_times = {}\n",
      "count = 0\n",
      "while date <= end_date:\n",
      "    yyyymmdd = date.strftime('%Y%m%d')\n",
      "    # print(type(yyyymmdd))\n",
      "    map_prices_df[yyyymmdd] = pd.DataFrame(columns=all_prices_df.columns)\n",
      "    \n",
      "    # print (count, len(daywise_start_end), date, end_date)\n",
      "    map_date_unix_times[yyyymmdd] = daywise_start_end[count]\n",
      "    map_prices_df[yyyymmdd] = all_prices_df[np.bitwise_and(daywise_start_end[count][0] < all_prices_df.index ,\n",
      "                                            all_prices_df.index < daywise_start_end[count][1])]\n",
      "    \n",
      "    # store symbol wise df\n",
      "    if map_prices_df[yyyymmdd].shape[0] != 0:\n",
      "        symbol = map_prices_df[yyyymmdd][symbol_list[0]].iloc[0]\n",
      "        if symbol not in symbol_df.keys():\n",
      "            symbol_df[symbol] = pd.DataFrame()\n",
      "\n",
      "        symbol_df[symbol] = pd.concat([symbol_df[symbol], map_prices_df[yyyymmdd]])\n",
      "    count += 1\n",
      "    date += BDay(1)\n",
      "\n",
      "# for key in map_prices_df.keys():\n",
      "#    print(key, map_prices_df[key].shape)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columns = ['30s'] + shortcode_list + symbol_list\n",
      "spread_symbol_df = {}\n",
      "\n",
      "for symbol in symbol_df.keys():\n",
      "    # print(symbol_df[symbol].describe())\n",
      "    if '30s' not in symbol_df[symbol].columns:\n",
      "        symbol_df[symbol].insert(0, '30s',symbol_df[symbol].index.to_series())\n",
      "    \n",
      "    symbol_df[symbol].columns = columns\n",
      "    spread_symbol_df[symbol] = (symbol_df[symbol][shortcode_list[0]] - symbol_df[symbol][shortcode_list[1]]).astype(float)\n",
      "    \n",
      "    print(symbol)\n",
      "    #print(symbol_df[symbol].index)\n",
      "    #print(spread_symbol_df[symbol].index)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lag = 100\n",
      "#print((spread.iloc[lag:] - spread.iloc[:-1*lag]))\n",
      "for key in sorted(spread_symbol_df.keys()):\n",
      "        this_spread = spread_symbol_df[key]\n",
      "        autocorrelation_plot(this_spread.iloc[lag:].as_matrix()[::lag])\n",
      "        \n",
      "        # autocorrelation_plot((this_spread.iloc[lag:].as_matrix()-this_spread.iloc[:-1*lag].as_matrix())[::lag])\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# spread_trend = spread - spread_ema\n",
      "\n",
      "# train_spread = spread \n",
      "\n",
      "# print (test_length, train_length, spread.shape)\n",
      "\n",
      "# train on 10 days, predict for today\n",
      "moving_window = int(2*num_trade_hours*60*10)\n",
      "index_increment = int(2*num_trade_hours*60)\n",
      "\n",
      "current_position = 0\n",
      "\n",
      "# print ('Data Separated', train_spread.shape)\n",
      "for lookback in [600, 480, 360, 240, 120]:\n",
      "\n",
      "    \n",
      "    price_list = []\n",
      "    for key in sorted(spread_symbol_df.keys()):\n",
      "        train_spread = spread_symbol_df[key]\n",
      "    \n",
      "        exch = key\n",
      "        exch = exch.replace(' ', '~')\n",
      "        trades_filename = work_dir + '/trades_' + '_'.join(shortcode_list).lower() + '_' + str(lookback) + '_' + exch\n",
      "        signal_filename = work_dir + '/signal_' + '_'.join(shortcode_list).lower() + '_' + str(lookback) + '_' + exch\n",
      "        approx_pnlfilename = work_dir + '/approx_pnl' + '_'.join(shortcode_list).lower() + '_' + str(lookback) + '_' + exch\n",
      "\n",
      "        signal_file = open(signal_filename, 'w')\n",
      "\n",
      "        trade_generator = TradeGenerator(shortcode_list, trades_filename, approx_pnlfilename,\n",
      "                                         commish=0.4, numbers_to_dollars=1639)\n",
      "    \n",
      "            \n",
      "        print_string = ''\n",
      "        current_index = lookback\n",
      "        while current_index < train_spread.shape[0] - moving_window - index_increment:\n",
      "\n",
      "            # >> print('CI', current_index, 'MV', moving_window, 'LB', lookback)\n",
      "\n",
      "            # last 10 days data\n",
      "            train_start_index = current_index\n",
      "            train_end_index = current_index + moving_window\n",
      "\n",
      "            y = (train_spread.iloc[train_start_index:train_end_index].as_matrix() -\n",
      "                 train_spread.iloc[train_start_index-lookback:train_end_index-lookback].as_matrix())\n",
      "\n",
      "            train_timestamps = train_spread.index[train_start_index:train_end_index]\n",
      "\n",
      "            # todays data\n",
      "            test_start_index = current_index + moving_window + 1\n",
      "            test_end_index = current_index + moving_window + index_increment\n",
      "\n",
      "            # >> print ('ST', test_start_index, test_end_index, train_start_index, train_end_index)\n",
      "            test_y = (train_spread.iloc[test_start_index:test_end_index].as_matrix() \n",
      "                      - train_spread.iloc[(test_start_index-lookback):(test_end_index-lookback)].as_matrix())\n",
      "\n",
      "            # compute the timestamps separately to print trades\n",
      "            test_timestamps = train_spread.index[test_start_index:test_end_index]\n",
      "\n",
      "            # non-ovelapping train and test y\n",
      "            non_overlapping_y = y[::lookback]\n",
      "            non_overlapping_test_y = test_y[::lookback]\n",
      "\n",
      "            # print ('Interval: ', lookback, ' Data Size: Train: ', non_overlapping_y.shape, ' Test: ', non_overlapping_test_y.shape)\n",
      "\n",
      "            current_index += index_increment\n",
      "\n",
      "            predictions = np.array([])\n",
      "            \n",
      "            for idx in range(non_overlapping_test_y.shape[0]):\n",
      "                # print ('ITER', idx, y)\n",
      "                model = ARIMA(non_overlapping_y, order=((1),0,0))\n",
      "                model_fit = model.fit()\n",
      "\n",
      "                prediction = model_fit.forecast()[0]\n",
      "                observation = non_overlapping_test_y[idx]\n",
      "\n",
      "                predictions = np.append(predictions, prediction)\n",
      "\n",
      "                non_overlapping_y = np.append(non_overlapping_y, observation)\n",
      "\n",
      "                ctime = test_timestamps[idx]\n",
      "                time_list = [symbol_df[key][shortcode_list[0]].astype(float).loc[ctime], symbol_df[key][shortcode_list[1]].astype(float).loc[ctime]]\n",
      "                price_list = time_list\n",
      "                if prediction >= threshold_vec[0] and current_position != 1:\n",
      "                    trade_generator.print_trades(ctime, [20, -20], time_list)\n",
      "                    trade_generator.compute_pnl(ctime, [20, -20], time_list)\n",
      "                    current_position = 1\n",
      "                elif prediction <= -1*threshold_vec[0] and current_position != -1:\n",
      "                    ctime = test_timestamps[idx]\n",
      "                    trade_generator.print_trades(ctime, [-20, 20], time_list)\n",
      "                    trade_generator.compute_pnl(ctime, [-20, 20], time_list)\n",
      "                    current_position = -1\n",
      "                elif prediction < threshold_vec[1] and prediction > -1*threshold_vec[1] and current_position != 0:\n",
      "                    trade_generator.print_trades(ctime, [0, 0], time_list)\n",
      "                    trade_generator.compute_pnl(ctime, [0, 0], time_list)\n",
      "                    current_position = 0\n",
      "\n",
      "                print_string += ('%s predicted=%f, expected=%f\\n' % (str(ctime), prediction, observation))\n",
      "\n",
      "        if current_position != 0:\n",
      "            pos = current_position*-20\n",
      "            trade_generator.print_trades(ctime, [pos, -1*pos], time_list)\n",
      "            trade_generator.compute_pnl(ctime, [pos, -1*pos], time_list)\n",
      "        \n",
      "        #print ('RESID', model_fit.resid)\n",
      "        residuals = pd.DataFrame(model_fit.resid)\n",
      "        residuals.plot()\n",
      "        print_string += ('%s\\n' % model_fit.summary())\n",
      "        print_string += ('ARPARAMS %d %f\\n' %( lookback, model_fit.arparams))\n",
      "        \n",
      "        print_string += ('M/STD RESID %d %f %f\\n' % (lookback, np.std(model_fit.resid), np.mean(model_fit.resid)))\n",
      "\n",
      "        print_string += ('MSE %d %f\\n' % (lookback, np.mean(predictions-non_overlapping_test_y)**2))\n",
      "        print_string += ('COR %d %f\\n' %( lookback, np.corrcoef(predictions, non_overlapping_test_y)[0][1]))\n",
      "        signal_file.write(print_string)\n",
      "        # break\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(train_spread.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}